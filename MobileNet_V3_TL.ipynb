{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyPUV/+tVrfVfh0t7AHRO7J1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JECzPUGwdRR1","executionInfo":{"status":"ok","timestamp":1603693842792,"user_tz":-540,"elapsed":1105,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_P3v-KnWlL2","executionInfo":{"status":"ok","timestamp":1603693908017,"user_tz":-540,"elapsed":64225,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"dbd4a42e-c38e-4880-f82e-0ca2222c6edf","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tf-nightly-gpu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tf-nightly-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/e5/aff89e0f764aa655cfc0f193e9769ec3fdffdc68c8fd9afaac6eab62466a/tf_nightly_gpu-2.5.0.dev20201025-cp36-cp36m-manylinux2010_x86_64.whl (394.2MB)\n","\u001b[K     |████████████████████████████████| 394.2MB 41kB/s \n","\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.3.3)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.4.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n","Collecting numpy~=1.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 237kB/s \n","\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.1)\n","Collecting tf-estimator-nightly~=2.4.0.dev\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/d2/2131f5a0f0d14bae7f4d332724748b9ca6746b0d32f5c76145f0707f47d8/tf_estimator_nightly-2.4.0.dev2020102301-py2.py3-none-any.whl (461kB)\n","\u001b[K     |████████████████████████████████| 471kB 52.9MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.2.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.3.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (2.10.0)\n","Collecting flatbuffers~=1.12.0\n","  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n","Collecting protobuf~=3.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 56.2MB/s \n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.6.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.32.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.15.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.2)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.10.0)\n","Collecting tb-nightly~=2.4.0.a\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1b/e51d99187dfd4de9ede5e1cfd5b69f740bf7f59f6b98cd19a59261f32d2d/tb_nightly-2.4.0a20201025-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 49.1MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.35.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf~=3.13.0->tf-nightly-gpu) (50.3.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (1.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (3.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly~=2.4.0.a->tf-nightly-gpu) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly-gpu) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly-gpu) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly-gpu) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly~=2.4.0.a->tf-nightly-gpu) (2.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.4.0.a->tf-nightly-gpu) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly-gpu) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly-gpu) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly-gpu) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.4.0.a->tf-nightly-gpu) (3.0.4)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly~=2.4.0.a->tf-nightly-gpu) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.4.0.a->tf-nightly-gpu) (3.2.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.4.0.a->tf-nightly-gpu) (3.1.0)\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, tf-estimator-nightly, flatbuffers, protobuf, tb-nightly, tf-nightly-gpu\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","Successfully installed flatbuffers-1.12 numpy-1.19.2 protobuf-3.13.0 tb-nightly-2.4.0a20201025 tf-estimator-nightly-2.4.0.dev2020102301 tf-nightly-gpu-2.5.0.dev20201025\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"v98DXjoVWq-H","executionInfo":{"status":"ok","timestamp":1603693917739,"user_tz":-540,"elapsed":2941,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.applications import MobileNetV3Large\n","from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.applications import ResNet50\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Conv2D\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Nadam, Adam\n","from sklearn.metrics import classification_report\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQKKIV7HXddr","executionInfo":{"status":"ok","timestamp":1603693941955,"user_tz":-540,"elapsed":21205,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"a1efc8b5-def3-4cc7-b70b-ebe1e15fa25a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WnU4bDzLXgsJ","executionInfo":{"status":"ok","timestamp":1603693944820,"user_tz":-540,"elapsed":530,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# directory creation\n","if not os.path.exists(\"drive/My Drive/colab/output\"):\n","    os.makedirs(\"drive/My Drive/colab/output\")\n","\n","if not os.path.exists(\"drive/My Drive/colab/model\"):\n","    os.makedirs(\"drive/My Drive/colab/model\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1Z_E-UucIJ1","executionInfo":{"status":"ok","timestamp":1603696783489,"user_tz":-540,"elapsed":657,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["BASE_PATH = \"drive/My Drive/colab/bed_dataset\"\n","WARMUP_PLOT_PATH = os.path.sep.join([\"drive/My Drive/colab/output\", \"warmup.png\"])\n","UNFROZEN_PLOT_PATH = os.path.sep.join([\"drive/My Drive/colab/model\", \"unfrozen.png\"])\n","\n","# VALUE INIT\n","IMG_SIZE = 224\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","base_learning_rate = 0.001\n","BATCH_SIZE = 32\n","initial_epochs = 5\n","fine_tune_epochs = 10\n","#total_epochs = initial_epochs - fine_tune_epochs\n","total_epochs = fine_tune_epochs\n","\n","# initialize the list of class label names\n","CLASSES = [\"clean\", \"unclean\"]"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"sw5liHGDdX1D","executionInfo":{"status":"ok","timestamp":1603696783489,"user_tz":-540,"elapsed":385,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["def plot_training(history, N, plotPath):\n","    # construct a plot that plots and saves the training history\n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n","    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n","    #plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n","    #plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n","    plt.title(\"Training Loss and Accuracy\")\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Loss/Accuracy\")\n","    plt.legend(loc=\"lower left\")\n","    plt.savefig(plotPath)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3pf8wVocRy4","executionInfo":{"status":"ok","timestamp":1603696783771,"user_tz":-540,"elapsed":395,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# derive the paths to the training, validation, and testing\n","# directories\n","trainPath = os.path.sep.join([BASE_PATH, \"train\"])\n","valPath = os.path.sep.join([BASE_PATH, \"val\"])\n","testPath = os.path.sep.join([BASE_PATH, \"test\"])\n","\n","# determine the total number of image paths in training, validation, \n","# and testing directories\n","totalTrain = len(list(paths.list_images(trainPath)))\n","totalVal = len(list(paths.list_images(valPath)))\n","totalTest = len(list(paths.list_images(testPath)))"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"FceydaV9cX4B","executionInfo":{"status":"ok","timestamp":1603696784119,"user_tz":-540,"elapsed":515,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# initialize the training data augmentation object\n","train_datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    zoom_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\")\n","\n","# initialize the validation/testing data augmentation object (which\n","# we'll be adding mean subtraction to)\n","val_datagen = ImageDataGenerator()\n","\n","# define the ImageNet mean subtraction (in RGB order) and set the\n","# mean subtraction value for each of the data augmentation\n","# objects\n","mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n","train_datagen.mean = mean\n","val_datagen.mean = mean"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"gptZBoI3cZqA","executionInfo":{"status":"ok","timestamp":1603696784820,"user_tz":-540,"elapsed":977,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"0b5492a7-7ac4-4421-f647-909aef841adc","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# initialize the training generator\n","train_batches = train_datagen.flow_from_directory(\n","    trainPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=True,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"categorical\") # categorical or binary\n","\n","# initialize the validation generator\n","validation_batches = val_datagen.flow_from_directory(\n","    valPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"categorical\")\n","\n","# initialize the testing generator\n","test_batches = val_datagen.flow_from_directory(\n","    testPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"categorical\")"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Found 213 images belonging to 2 classes.\n","Found 40 images belonging to 2 classes.\n","Found 40 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sv2ZzvR-c0Eq","executionInfo":{"status":"ok","timestamp":1603696786358,"user_tz":-540,"elapsed":2266,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["# Create the base model from the pre-trained model \n","#base_model = MobileNetV2(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False, layers=tf.keras.layers) # added layers=tf.keras.layers for batch normalization problem: still not working\n","#base_model = ResNet50(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False, layers=tf.keras.layers) # added layers=tf.keras.layers for batch normalization problem: still not working\n","\n","#base_model = MobileNetV3Large(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False, layers=tf.keras.layers, alpha=1.0, minimalistic=True, backend=tf.keras.backend, models=tf.keras.models, utils=tf.keras.utils)\n","base_model = MobileNetV3Large(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False, alpha=1.0, minimalistic=True)\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Flatten(name=\"flatten\")(x)\n","# let's add a fully-connected layer\n","#x = Dense(512, activation=\"relu\")(x) # VGG16\n","x = Dense(512, activation=\"relu\")(x) # mobilenetv2\n","x = Dropout(0.8)(x)\n","# and a logistic layer -- let's say we have config2.CLASSES classes\n","predictions = Dense(len(CLASSES), activation=\"softmax\")(x)\n","\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pQ_YRrSc5kP","executionInfo":{"status":"ok","timestamp":1603696786359,"user_tz":-540,"elapsed":2013,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"a1521c02-1a6c-4de5-d1a7-cda51661f3c7","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional InceptionV3 layers\n","#for layer in base_model.layers:\n","#    layer.trainable = False\n","    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n","    #if isinstance(layer, tf.python.keras.layers.normalization_v2.BatchNormalization):\n","        #layer._per_input_updates = {}\n","\n","# loop over the layers in the model and show which ones are trainable\n","# or not\n","\n","base_model.trainable = True\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 50\n","\n","# for layer in base_model.layers[:fine_tune_at]:\n","#     if type(layer) != type(base_model.layers[3]):\n","#         layer.trainable = False\n","\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","for layer in base_model.layers:\n","    print(\"{}: {}\".format(layer, layer.trainable))\n","\n","print('This is the number of trainable weights '\n","      'after freezing the conv base:', len(model.trainable_weights))"],"execution_count":75,"outputs":[{"output_type":"stream","text":["<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fb0a3195860>: False\n","<tensorflow.python.keras.layers.preprocessing.image_preprocessing.Rescaling object at 0x7fb0a3195b00>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f5a9a90>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0d6716a20>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a3bf7c88>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a0216b38>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a00a31d0>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a00a3438>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a311ff98>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3d9b978>: False\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb1210a51d0>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a0670320>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a0c8afd0>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a315f4e0>: False\n","<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fb0a02f2fd0>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb09ca28390>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3159a20>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a315f940>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f023e80>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3153048>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a316bc50>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3153438>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a3153128>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a31b1fd0>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a31455c0>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a311f550>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a3101e48>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3119240>: False\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb0a3101c50>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a3101ef0>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a31118d0>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a3111128>: False\n","<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fb0a30f6cf8>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a3101cf8>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30f6c50>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a316bf28>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a3159e10>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a31459e8>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a31b14e0>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3153c18>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a3137b00>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a31068d0>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a31063c8>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a31ac9e8>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a30b5be0>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a31b19b0>: False\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb0a31193c8>: False\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a3153b00>: False\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30cf1d0>: False\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a30bee10>: False\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a30b5f60>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30d9780>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a30d9710>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a30ec208>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30cfb70>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb0a30cf128>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a30e0a90>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30c7a20>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a30cf5c0>: True\n","<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fb0a3119e48>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a30be4a8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30ec6a0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a30ecd68>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a3086f28>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30866d8>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a30323c8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a3086b00>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a30a19b0>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a30ecda0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30864e0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a303b320>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a304dac8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a303bf60>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb09f068940>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09cac8ef0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f025fd0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09f025668>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb09e491c50>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f066710>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb12a327048>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f0666a0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a067eac8>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb09e46cc18>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09cac5ac8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a30a89e8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a3046208>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb09f5f22e8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a063e4a8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a261ef28>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a063ecc0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09cac6518>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb09cabfd30>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09cac54e0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a0b85fd0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a0580780>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a0c4ca90>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09e3aeac8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09e47b128>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a0c4ce80>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a04f15f8>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a056d5f8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f0671d0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a0c71630>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a4145c50>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a4145518>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a0c71518>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a0646198>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a4145160>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb09f0674a8>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09e4c8f60>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0d66fc9e8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09e4c8400>: True\n","<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fb0a0c17128>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb09f0679b0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09eff2d30>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a0c185c0>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a43badd8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb0a0580ba8>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09eff2588>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09cac69e8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0a261eb70>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a0b852b0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f5f2ba8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09e46c9b0>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f0668d0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09e491b70>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb0a303bef0>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb0a40a24e0>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f0852b0>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09f07f470>: True\n","<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7fb0a40a29e8>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f07a6d8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb09f06f7b8>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f07f438>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f0c56a0>: True\n","<tensorflow.python.keras.layers.merge.Add object at 0x7fb09f0ae208>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f0cd908>: True\n","<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb09f127748>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb1210ad7f0>: True\n","<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb09f07add8>: True\n","<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fb0d6747be0>: True\n","This is the number of trainable weights after freezing the conv base: 96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"atHhbsxcc__N","executionInfo":{"status":"ok","timestamp":1603696886428,"user_tz":-540,"elapsed":99031,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"9d8438af-8c92-4894-f2a8-df3728be5d09","colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["print(\"[INFO] compiling model...\")\n","#opt = SGD(lr=base_learning_rate, momentum=0.9, decay=base_learning_rate/initial_epochs)\n","opt = Adam(lr=base_learning_rate, decay=base_learning_rate/initial_epochs)\n","#opt = RMSprop(lr=base_learning_rate, decay=base_learning_rate/initial_epochs)\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]) #binary_crossentropy  categorical_crossentropy\n","\n","# train the head of the network for a few epochs (all other layers\n","# are frozen) -- this will allow the new FC layers to start to become\n","# initialized with actual \"learned\" values versus pure random\n","print(\"[INFO] training head...\")\n","history = model.fit(train_batches,\n","    epochs=initial_epochs,\n","    validation_data=validation_batches,\n","    steps_per_epoch=totalTrain // BATCH_SIZE,\n","    validation_steps=totalVal // BATCH_SIZE)\n","\n","# reset the testing generator and evaluate the network after\n","# fine-tuning just the network head\n","print(\"[INFO] evaluating after fine-tuning network head...\")\n","test_batches.reset()\n","predIdxs = model.predict(x=test_batches, steps=(totalTest // BATCH_SIZE) + 1)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print(classification_report(test_batches.classes, predIdxs, target_names=test_batches.class_indices.keys()))\n","#plot_training(history, initial_epochs, WARMUP_PLOT_PATH)\n","model.save(\"model.h5\", save_format=\"h5\")"],"execution_count":76,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n","[INFO] training head...\n","Epoch 1/5\n","6/6 [==============================] - 22s 3s/step - loss: 1.5282 - accuracy: 0.4605 - val_loss: 0.4404 - val_accuracy: 0.9062\n","Epoch 2/5\n","6/6 [==============================] - 18s 3s/step - loss: 0.6050 - accuracy: 0.8095 - val_loss: 0.2044 - val_accuracy: 0.9062\n","Epoch 3/5\n","6/6 [==============================] - 17s 3s/step - loss: 0.2567 - accuracy: 0.9409 - val_loss: 0.2150 - val_accuracy: 0.8750\n","Epoch 4/5\n","6/6 [==============================] - 18s 3s/step - loss: 0.2013 - accuracy: 0.9319 - val_loss: 0.2357 - val_accuracy: 0.9062\n","Epoch 5/5\n","6/6 [==============================] - 18s 3s/step - loss: 0.1628 - accuracy: 0.9306 - val_loss: 0.2084 - val_accuracy: 0.9062\n","[INFO] evaluating after fine-tuning network head...\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb0a07db400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","              precision    recall  f1-score   support\n","\n","       clean       0.77      1.00      0.87        20\n","     unclean       1.00      0.70      0.82        20\n","\n","    accuracy                           0.85        40\n","   macro avg       0.88      0.85      0.85        40\n","weighted avg       0.88      0.85      0.85        40\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yz7IiO8-d4hL","executionInfo":{"status":"ok","timestamp":1603678408198,"user_tz":-540,"elapsed":602,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"f0f9d63b-8cd1-42e3-ae26-4392b1ca5577","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["history_dict = history.history\n","print(history_dict.keys())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["dict_keys(['loss', 'accuracy'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u30fqehtrotU","executionInfo":{"status":"ok","timestamp":1603679758573,"user_tz":-540,"elapsed":705,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}},"outputId":"a08cab91-ccb0-4409-bdc1-0d9a61eb4e5a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(base_model.layers[3]) == type(base_model.layers[6])"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"4yAujhLRv7NA","executionInfo":{"status":"ok","timestamp":1603696898652,"user_tz":-540,"elapsed":860,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["model.save(\"model.h5\", save_format=\"h5\")"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwpSMC5TwWHf","executionInfo":{"status":"ok","timestamp":1603696899120,"user_tz":-540,"elapsed":869,"user":{"displayName":"Jin Wook Huh","photoUrl":"","userId":"06838297299533370542"}}},"source":["!cp model.h5 \"drive/My Drive/colab/model/model.h5\""],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtDBPJBAJX_U"},"source":[""],"execution_count":null,"outputs":[]}]}